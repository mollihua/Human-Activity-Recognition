<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>1. Introduction</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>1. Introduction</h2>

<p>Data collected from personal care devices can be used to quantify self movement so as to improve personal health. The goal of this study is to use the data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to evaluate how well they do it. In particular, the outcome variable is classe, which has 5 levels corresponding to correct and incorrect ways of barbell lifts.  </p>

<p>Data source: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>.  </p>

<p>Reference: Ugulino, Wallace, et al. &quot;Wearable computing: accelerometersâ€™ data classification of body postures and movements.&quot; Advances in Artificial Intelligence-SBIA 2012. Springer Berlin Heidelberg, 2012. 52-61.  </p>

<h2>2. Data preprocessing</h2>

<pre><code class="r"># load data
datax &lt;- read.csv(&quot;pml-training.csv&quot;,na.strings = c(&quot;NA&quot;,&quot;&quot;,&quot;#DIV/0!&quot;))

# remove the columns with high NA composition (&gt;75% is NA) 
nr &lt;- nrow(datax)
nc &lt;- ncol(datax)
indna &lt;- c()
for (i in 1:nc) {
    nacheck &lt;- sum(is.na(datax[,i]))&gt;0.75*nr
    if (nacheck==1) {
        indna &lt;- c(indna,i)
    }
}
datax2 &lt;- datax[,-indna]

# keep the data of complete cases
datax3 &lt;- datax2[complete.cases(datax2),]
dim(datax2)
</code></pre>

<pre><code>## [1] 19622    60
</code></pre>

<pre><code class="r">dim(datax3)
</code></pre>

<pre><code>## [1] 19622    60
</code></pre>

<pre><code class="r"># remove meaningless columns for prediction
indrm &lt;- grep(&quot;timestamp|X|user_name|new_window&quot;, names(datax3))
datax4 &lt;-datax3[,-indrm]
dim(datax4)
</code></pre>

<pre><code>## [1] 19622    54
</code></pre>

<pre><code class="r">remove(datax2)
remove(datax3)
</code></pre>

<h2>3. Model Fitting and Predictions</h2>

<h4>Data preprocessing</h4>

<p>Split the dataset &quot;plm-training.csv&quot; into a training set (60%) and and a testing set (40%).  </p>

<pre><code class="r"># split the dataset &quot;pml-training.csv&quot; into a training set and a testing set
library(caret)
library(ggplot2)

inTrain &lt;- createDataPartition(y=datax4$classe, p=0.6, list=FALSE)
training &lt;- datax4[inTrain,]
testing &lt;- datax4[-inTrain,]
dim(training)
</code></pre>

<pre><code>## [1] 11776    54
</code></pre>

<pre><code class="r">dim(testing)
</code></pre>

<pre><code>## [1] 7846   54
</code></pre>

<h4>Model fitting</h4>

<p>The random forest algorithm is chosen to train the training dataset, because random forest gives high accuracy. Here the outcome is classe, and all the other variables are considered predictors.  </p>

<pre><code class="r">set.seed(1299)

# use 5-fold cross-validations as the resampling scheme 
fitControl &lt;- trainControl(method = &quot;cv&quot;, number = 5)
modfit &lt;- train(classe~., data=training, method=&quot;rf&quot;,  trControl=fitControl, verbose=FALSE)
modfit
</code></pre>

<pre><code>## Random Forest 
## 
## 11776 samples
##    53 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 9420, 9420, 9421, 9422, 9421 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
##    2    0.9910834  0.9887199  0.001899622  0.002403137
##   27    0.9958388  0.9947362  0.001860876  0.002354259
##   53    0.9943101  0.9928023  0.001550424  0.001961298
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 27.
</code></pre>

<pre><code class="r">ggplot(modfit)
</code></pre>

<p><img src="figure/unnamed-chunk-3-1.png" alt="plot of chunk unnamed-chunk-3"> </p>

<pre><code class="r">modfit$finalModel
</code></pre>

<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, verbose = FALSE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 27
## 
##         OOB estimate of  error rate: 0.27%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 3346    1    0    0    1 0.0005973716
## B    7 2268    4    0    0 0.0048266784
## C    0    7 2047    0    0 0.0034079844
## D    0    0    7 1922    1 0.0041450777
## E    0    1    0    3 2161 0.0018475751
</code></pre>

<p>The result suggested that the final value for the model is mtry=27. This is because the accuracy is the highest when mtry=27. The corresponding accuracy is 0.9958388 The in sample error is 1-0.9958388=0.0041612.  </p>

<h4>Cross validation</h4>

<p>In random forests, generally there is no need for cross-validation or a separate test set to get an unbiased estimate of the test set error, since cross-validation has been estimated internally. In this study, we assume the training dataset and the testing dataset are randomized, and therefore we should expect both the in sample error (from the training dataset) and out of sample error (from the testing dataset) are unbiased.  </p>

<h4>Out of sample error</h4>

<p>Use the model to predict the out of sample error on the testing dataset.  </p>

<pre><code class="r">testingout &lt;- predict(modfit, newdata=testing)
testingtbl&lt;-table(testingout, testing$classe)
testing_accuracy &lt;- sum(diag(testingtbl))/sum(testingtbl)
testing_err &lt;- 1-testing_accuracy
testing_err
</code></pre>

<pre><code>## [1] 0.002039256
</code></pre>

<p>That is, the out of sample error is 0.0020393.  </p>

<h4>Use the prediction model to predict 20 different test cases.</h4>

<pre><code class="r"># load the test dataset
testx&lt;-read.csv(&quot;pml-testing.csv&quot;,na.strings = c(&quot;NA&quot;,&quot;&quot;,&quot;#DIV/0!&quot;))

# remove the columns with high NA composition (&gt;75% is NA) 
nrtest &lt;- nrow(testx)
nctest &lt;- ncol(testx)
indnatest &lt;- c()
for (i in 1:nctest) {
    nacheck &lt;- sum(is.na(testx[,i]))&gt;0.75*nrtest
    if (nacheck==1) {
        indnatest &lt;- c(indnatest,i)
    }
}
testx2 &lt;- testx[,-indnatest]

# keep the complete cases
testx3 &lt;- testx2[complete.cases(testx2),]
dim(testx2)
</code></pre>

<pre><code>## [1] 20 60
</code></pre>

<pre><code class="r">dim(testx3)
</code></pre>

<pre><code>## [1] 20 60
</code></pre>

<pre><code class="r"># remove meaningless columns for prediction
indrmtest &lt;- grep(&quot;timestamp|X|user_name|new_window&quot;, names(testx3))
testx4 &lt;-testx3[,-indrmtest]
dim(testx4)
</code></pre>

<pre><code>## [1] 20 54
</code></pre>

<pre><code class="r"># predict test dataset outcome
testxout &lt;- predict(modfit, newdata=testx)
print(testxout)
</code></pre>

<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
</code></pre>

</body>

</html>
