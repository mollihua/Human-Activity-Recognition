rexp(10,0.2)
f<-rexp(10,0.2)
sd(f)
5/sqrt(10)
f<-rexp(100,0.2)
5/sqrt(10)
sd(f)
mean(f)
f<-rexp(1000,0.2)
mean(f)
sd(f)
mns=NULL
for (i in 1:10000) mns=c(mns, mean(rexp(40,0.2)))
qplot(mns)
library(ggplot2)
qplot(mns)
dim(mns)
length(mns)
mean(mns)
sd(mns)
for (i in 1:10000) mns=c(mns, mean(rexp(100,0.2)))
sd(mns)
5/sqrt(100)
for (i in 1:1000) mns=c(mns, mean(rexp(1000,0.2)))
5/sqrt(1000)
sd)mns
sd(mns)
length(mns)
mns=NULL
for (i in 1:1000) mns=c(mns, mean(rexp(1000,0.2)))
sd(mns)
5/sqrt(1000)
for (i in 1:1000) mns=c(mns, mean(rexp(10000,0.2)))
mns=NULL
for (i in 1:1000) mns=c(mns, mean(rexp(10000,0.2)))
5/sqrt(10000)
sd(mns)
x <- rnorm(20)
x
m <- matrix(c(1:6),2,3)
m
apply(m,1,median)
data("InsectSprays")
boxplot(count~spray, data=InsectSprays)
data(InsectSprays)
boxplot(count~spray, data=InsectSprays)
boxplot(count~spray, data=InsectSprays)
subdata <- InsectSprays[InsectSprays$spray %in% c("B","C")]
subdata <- InsectSprays[InsectSprays$spray %in% c("B","C"),]
subdata
head(subdsat)
head(subdsata)
head(subdata)
tail(subdata)
y<-subdata$count
group<-as.character(subdata$spray)
testStat <- functin(w,g) mean(w[g=="B"] ) - mean(w[g=="C"])
testStat <- functin(w,g) mean(w[g=="B"]) - mean(w[g=="C"])
testStat <- functin(w,g) mean(w[g=="B"]) - mean(w[g=="C"])
testStat <- function(w,g) mean(w[g=="B"]) - mean(w[g=="C"])
observedStat <- testStat(y, group)
observedStat
permutation <- sapply(1:2,function(i)) testStat(y,sample(group))
permutation <- sapply(1:2,function(i)) testStat(y,sample(group)))
permutation <- sapply(1:10,function(i)) testStat(y,sample(group)))
permutation <- sapply(1:10,function(i) testStat(y,sample(group)))
permutation
sample(group)
sample(group)
y
testStat(y,sample(group))
testStat(y,sample(group))
testStat(y,sample(group))
testStat(y,sample(group))
testStat(y,sample(group))
mean(permutation)
mean(permutation>observedStat)
permutation <- sapply(1:10,function(i) testStat(y,sample(group)))
mean(permutation>observedStat)
library(data.table)
d<- data.frame("sub"=c(1,2,3,4,5))
d<- data.frame("sub"=c(1,2,3,4,5), "baseline"=c(140,138,150,148,135),"week2"=c(132,135,151,146,130))
d
t.test(week2 ~ baseline, paired=TRUE, var.equal=TRUE)
t.test(d$week2 ~ d$baseline, paired=TRUE, var.equal=TRUE)
t.test(week2 ~ baseline, paired=TRUE, var.equal=TRUE, data=d)
t.test(week2 - baseline, paired=TRUE, var.equal=TRUE, data=d)
t.test(week2,baseline, paired=TRUE, var.equal=TRUE, data=d)
t.test(week2,baseline, paired=TRUE, var.equal=TRUE, data=d)
d
t.test(baseline, week2 paired=TRUE, var.equal=TRUE, data=d)
t.test(baseline, week2, paired=TRUE, var.equal=TRUE, data=d)
t.test(d$baseline, d$week2, paired=TRUE, var.equal=TRUE)
t.test(d$baseline, d$week2, paired=TRUE, var.equal=FALSE)
t.test(d$baseline, d$week2, paired=TRUE)
t(0.08652,4)
qt(1-0.08652,4)
qt(1-0.5*0.08652,4)
qt(1-0.5*0.05,10000)
qt(1-0.05,10000)
?qt
?t.test
u0<-9
u0<-1100
sd<30
sd<-30
n<-9
u0+qt(.975,8)*sd/sqrt(9)
u0-qt(.975,8)*sd/sqrt(9)
?pt
pt(q=0.75,df=3)
pt(q=0.75,df=3)-1
pt(q=0.75,df=3,lower.tail=FALSE)
qt(p=0.75,df=3,lower.tail=FALSE)
qt(p=0.75,df=3)
qt(p=0.975,df=1000)
pt(q=1.92,df=1000)
pt(q=1.96,df=1000)
pt(q=1.96,df=1000, lower.tail=FALSE)
pt(q=1.96,df=1000, lower.tail=FALSE)
pt(q=,df=1000, lower.tail=FALSE)
pbinom(2,size=4,lower.tall=FALSE)
pbinom(2,size=4,prob=0.75,lower.tall=FALSE)
pbinom(2,size=4,prob=0.75,lower.tail=FALSE)
pbinom(2,size=4,prob=0.5,lower.tail=FALSE)
pbinom(2,size=4,prob=0.75,lower.tail=FALSE)
pbinom(2,size=4,prob=0.75,lower.tail=TURE)
pbinom(2,size=4,prob=0.75,lower.tail=TRUE)
pbinom(3,size=4,prob=0.5,lower.tail=TRUE)
pbinom(2,size=4,prob=0.5,lower.tail=TRUE)
pbinom(2,size=4,prob=0.75,lower.tail=FALSE)
pbinom(3,size=4,prob=0.75,lower.tail=FALSE)
pbinom(2,size=4,prob=0.5,lower.tail=FALSE)
pbinom(3,size=4,prob=0.5,lower.tail=FALSE)
pnorm(10,size=1787,prob=0.01,lower.tail=FALSE)
pnorm(n=10,size=1787,prob=0.01,lower.tail=FALSE)
pnorm(10/1787)
pbinom(9,size=1787, prob=0.01, lower.tail=FALSE
)
pbinom(9,size=1787, prob=0.01, lower.tail=FALSE)-pbinom(10,size=1787,prob=0.01,lower.tail = FALSE)
pbinom(9,size=1787, prob=0.01, lower.tail=TRUE)
pbinom(10,size=1787, prob=0.01, lower.tail=TRUE)
power.t.test(delta=0.01,sd=0.04,sig.level=0.10,alternative = "one.sided")
power.t.test(delta=0.01,sd=0.04,sig.level=0.10,alternative = "one.sided")$n
power.t.test(delta=0.01,sd=0.04,power=0.9,sig.level=0.05,alternative = "one.sided")$n
power.t.test(delta=0.01,sd=0.04,power=0.9,sig.level=0.05,alternative = "one.sided")$n
power.t.test(delta=0.01,sd=0.04,power=0.9,alternative = "one.sided")$n
power.t.test(delta=0.01,sd=0.04,power=0.9,sig.level=.25alternative = "one.sided")$n
power.t.test(delta=0.01,sd=0.04,power=0.9,sig.level=.25,alternative = "one.sided")$n
power.t.test(delta=0.01,sd=0.04,power=0.9,sig.level=.1,alternative = "one.sided")$n
?power.t.test
power.t.test(delta=0.01,sd=0.04,power=0.9,sig.level=.025,alternative = "one.sided")$n
power.t.test(delta=0.01,sd=0.04,power=0.9,sig.level=.05,type="paired",alternative = "one.sided")$n
power.t.test(n=100,delta=0.01,sd=0.04,sig.level=.05,type="paired",alternative = "one.sided")$power
m1=-3;m2=1
sd1=1.5;sd2=1.8
n1=9,n2=9
n1=9;n2=9
sp <-sqrt( ((n1-1)*sd1^2+(n2-1)*sd2^2)/(n1+n2-2))
ttest<-(n2-n1)/(sp*(sqrt(1/n1+1/n2)))
ttest
sp
ttest<-(m2-m1)/(sp*(sqrt(1/n1+1/n2)))
ttest
t(n1+n2-2,0.05)
qt(.95,n1+n2-2)
qt(.975,n1+n2-2)
qt(.995,n1+n2-2)
d
modfit <- train(factor(classe)~., data=training, method="rf", prox=TRUE, ntree=500, mtry=5)
inTrain <- createDataPartition(y=datax4$classe, p=0.01, list=FALSE)
library(caret)
library(caret)
inTrain <- createDataPartition(y=datax4$classe, p=0.01, list=FALSE)
2. Data Analysis using Machine Learning Algorithm
# load data
datax <- read.csv("pml-training.csv")
# remove the columns with high NA composition (>75% is NA)
nr <- nrow(datax)
nc <- ncol(datax)
indna <- c()
for (i in 1:nc) {
nacheck <- sum(is.na(datax[,i]))>0.75*nr
if (nacheck==1) {
indna <- c(indna,i)
}
}
datax2 <- datax[,-indna]
# keep the data of complete cases
datax3 <- datax2[complete.cases(datax2),]
dim(datax2)
dim(datax3)
# remove meaningless columns for prediction
indrm <- grep("timestamp|X|user_name|new_window", names(datax3))
datax4 <-datax3[,-indrm]
dim(datax4)
setwd("~/Desktop/pl")
setwd("~/Desktop/pml_project/")
# load data
datax <- read.csv("pml-training.csv")
# remove the columns with high NA composition (>75% is NA)
nr <- nrow(datax)
nc <- ncol(datax)
indna <- c()
for (i in 1:nc) {
nacheck <- sum(is.na(datax[,i]))>0.75*nr
if (nacheck==1) {
indna <- c(indna,i)
}
}
datax2 <- datax[,-indna]
# keep the data of complete cases
datax3 <- datax2[complete.cases(datax2),]
dim(datax2)
dim(datax3)
# remove meaningless columns for prediction
indrm <- grep("timestamp|X|user_name|new_window", names(datax3))
datax4 <-datax3[,-indrm]
dim(datax4)
remove(datax2)
remove(datax3)
library(caret)
library(ggplot2)
inTrain <- createDataPartition(y=datax4$classe, p=0.01, list=FALSE)
training <- datax4[inTrain,]
testing <- datax4[-inTrain,]
dim(training)
dim(testing)
set.seed(1299)
modfit <- train(factor(training$classe)~., data=training, method="rf", prox=TRUE, ntree=500, mtry=5)
modfit <- train(factor(training$classe)~., data=training, method="rf", prox=TRUE, ntree=500, mtry=5)
modfit <- train(factor(training$classe)~., data=training, method="rf", prox=TRUE, mtry=5)
modfit <- train(facto(classe)~., data=training, method="rf", prox=TRUE, mtry=5)
modfit <- train(factor(classe)~., data=training, method="rf", prox=TRUE, mtry=5)
warnings()
warnings()
?train
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
## repeated ten times
repeats = 10)
modfit <- train(factor(classe)~., data=training, method="rf", trControl=fitControl)
modfit <- train(factor(classe)~., data=training, method="gbm", trControl=fitControl)
modfit <- train(classe~., data=training, method="gbm", trControl=fitControl)
str(datax4)
datax4$kurtosis_roll_belt
str(datax4)
datax4$skewness_yaw_dumbbell
str(datax4)
datax <- read.csv("pml-training.csv",na.strings = c("NA","","#DIV/0!"))
# remove the columns with high NA composition (>75% is NA)
nr <- nrow(datax)
nc <- ncol(datax)
indna <- c()
for (i in 1:nc) {
nacheck <- sum(is.na(datax[,i]))>0.75*nr
if (nacheck==1) {
indna <- c(indna,i)
}
}
datax2 <- datax[,-indna]
datax3 <- datax2[complete.cases(datax2),]
dim(datax2)
dim(datax3)
# remove meaningless columns for prediction
indrm <- grep("timestamp|X|user_name|new_window", names(datax3))
datax4 <-datax3[,-indrm]
dim(datax4)
remove(datax2)
remove(datax3)
library(caret)
library(ggplot2)
inTrain <- createDataPartition(y=datax4$classe, p=0.01, list=FALSE)
training <- datax4[inTrain,]
testing <- datax4[-inTrain,]
dim(training)
dim(testing)
modfit <- train(classe~., data=training, method="gbm", trControl=fitControl)
modfit <- train(factor(classe)~., data=training, method="gbm", trControl=fitControl, verbose=FALSE)
summary(modfit)
modfit <- train(factor(classe)~., data=training, method="rf", trControl=fitControl, verbose=FALSE)
summary(modfit)
modfit
modfit$finalModel
plot(modfit)
ggplot(modfit)
inTrain <- createDataPartition(y=datax4$classe, p=0.75, list=FALSE)
training <- datax4[inTrain,]
testing <- datax4[-inTrain,]
dim(training)
dim(testing)
set.seed(1299)
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
modfit <- train(classe~., data=training, method="rf",  trControl=fitControl, verbose=FALSE)
inTrain <- createDataPartition(y=datax4$classe, p=0.6, list=FALSE)
training <- datax4[inTrain,]
testing <- datax4[-inTrain,]
dim(training)
dim(testing)
set.seed(1299)
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
modfit <- train(classe~., data=training, method="rf",  trControl=fitControl, verbose=FALSE)
fitControl <- trainControl(method = "repeatedcv", number = 5, repeats = 3)
modfit <- train(classe~., data=training, method="rf",  trControl=fitControl, verbose=FALSE)
fitControl <- trainControl(method = "oob", number = 5, repeats = 3)
modfit <- train(classe~., data=training, method="rf",  trControl=fitControl, verbose=FALSE)
fitControl <- trainControl(method = "cv", number = 5, repeats = 3)
modfit <- train(classe~., data=training, method="rf",  trControl=fitControl, verbose=FALSE)
modfit
plot(modfit)
ggplot(modfit)
1-0.9952446
testingout <- predict(modfit, newdata=testing)
testingout
table(testingout, testing$classe)
testingtbl<-table(testingout, testing$classe)
diag(testingtbl)
sum(testingaccu <- sum(diag(testingtbl))/sum(testingtbl))
testingaccu <- sum(diag(testingtbl))/sum(testingtbl)
testingaccu
testingaccu-1
list.files()
testx<-read.csv("plm-testing.csv")
testxout <- predict(modfit, newdata=testx)
testx<-read.csv("pml-testing.csv"
testx<-read.csv("pml-testing.csv",na.strings = c("NA","","#DIV/0!"))
testx<-read.csv("pml-testing.csv",na.strings = c("NA","","#DIV/0!"))
testx<-read.csv("pml-testing.csv",na.strings = c("NA","","#DIV/0!"))
# remove the columns with high NA composition (>75% is NA)
nrtest <- nrow(testx)
nctest <- ncol(testx)
indnatest <- c()
for (i in 1:nctest) {
nacheck <- sum(is.na(testx[,i]))>0.75*nr
if (nacheck==1) {
indnatest <- c(indnatest,i)
}
}
testx2 <- testx[,-indnatest]
# keep the data of complete cases
testx3 <- testx2[complete.cases(testx2),]
dim(testx2)
dim(testx3)
# remove meaningless columns for prediction
indrmtest <- grep("timestamp|X|user_name|new_window", names(testx3))
testx4 <-testx4[,-indrm]
dim(testx4)
# predict test dataset outcome
testxout <- predict(modfit, newdata=testx)
testxout
answers=testxout
answers
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
xxx<-pml_write_files(answers)
xxx
answers
answers=c(testxout)
answers
answers=character(testxout)
answers=factor(testxout)
answers
xxx<-pml_write_files(answers)
xxx
list.files()
answers
pml_write_files(testxout)
list.files()
testx<-read.csv("pml-testing.csv",na.strings = c("NA","","#DIV/0!"))
nrtest <- nrow(testx)
nctest <- ncol(testx)
indnatest <- c()
for (i in 1:nctest) {
nacheck <- sum(is.na(testx[,i]))>0.75*nr
if (nacheck==1) {
indnatest <- c(indnatest,i)
}
}
testx2 <- testx[,-indnatest]
indnatest
for (i in 1:nctest) {
nacheck <- sum(is.na(testx[,i]))>0.75*nr
if (nacheck==1) {
indnatest <- c(indnatest,i)
}
}
indnatest
nrtest <- nrow(testx)
nctest <- ncol(testx)
indnatest <- c()
for (i in 1:nctest) {
nacheck <- sum(is.na(testx[,i]))>0.75*nrtest
if (nacheck==1) {
indnatest <- c(indnatest,i)
}
}
testx2 <- testx[,-indnatest]
testx3 <- testx2[complete.cases(testx2),]
dim(testx2)
dim(testx3)
indrmtest <- grep("timestamp|X|user_name|new_window", names(testx3))
testx4 <-testx4[,-indrm]
dim(testx4)
# predict test dataset outcome
testxout <- predict(modfit, newdata=testx)
testxout
indrmtest <- grep("timestamp|X|user_name|new_window", names(testx3))
testx4 <-testx3[,-indrmtest]
dim(testx4)
# predict test dataset outcome
testxout <- predict(modfit, newdata=testx)
testxout
setwd("./PML_Project/")
